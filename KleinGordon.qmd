---
title: "Wightman Axioms for free scalar quantum field"
bibliography: references.bib
---
Article last updated: January 16, 2026

I'm writing this article so that I can learn Theorem 3.1 of 
Prof. Christian Brennecke's constructive quantum field theory
notes @BrenneckeCQFT. The statement of the theorem is as follows. 

::: {.callout-note title="Theorem 3.1"}
Consider the strongly continuous unitary representation $\Gamma(U)$ (gamma of U)
of $\mathcal{P}_{+}^{\uparrow}$ (P plus up) on 
$\mathcal{H} = \mathcal{F}_s(L^2(S_m^+))$ (Bosonic Fock space built over $L^2$
of the mass shell of mass $m$)
with Fock space vacuum $\Omega = (1,0,0,\cdots) \in \mathcal{H}$
and let $\phi = (\phi(f))_{f \in \mathcal{S}(\mathbb R^4)}$
(family of operators indexed by 
Schwartz functions on $\mathbb R^4$)
be defined as (3.14):
\begin{equation}
\phi(f) = (2\pi)^{1/2} \int_{S_m^+} \lambda_m(dp) \tilde{f}(p) a_p + (2\pi)^{1/2} \int_{S_m^+} \lambda_m(dp) \tilde{f}(p) a_p^*.
\end{equation}
Then $(\mathcal{H}, \Gamma(U), \Omega, \phi)$ 
satisfies the Wightman axioms and 
\begin{equation}
(\square + m^2) \phi = 0
\end{equation}
in the sense of operator-valued distributions.
:::

#### The operator valued distribution (3.14)
Let me clarify (3.14) for myself.
Recall that the creation and annihilation
operators depend on some function $f \in L^2(\mathcal{M})$, 
where in this case $\mathcal{M} = S_m^+$.
Only once you have some $f$ can you talk about
an operator from the infinite tensor product 
space $\mathcal{F}_s$ to itself.
That is why I can write
\begin{equation}
a(\sqrt{ 2 \pi } \tilde{f} ) : \mathcal{F}_s \to \mathcal{F}_s,
\end{equation}
and this object is defined in section 2.4
in @BrenneckeCQFT.

Next, I want to phrase (3.14) directly 
in terms of rigorously defined objects. 
I'll use the identities
\begin{equation}
a(f) =: \int_{\mathbb R^d} dx \overline{f}(x) a_x
\end{equation}
and 
\begin{equation}
a^*(g) =: \int_{\mathbb R^d} dx g(x) a_x^*
\end{equation}
found in section 2.4 of Brennecke's notes. 
It follows that 
\begin{equation}
(2\pi)^{1/2} \int_{S_m^+} \lambda_m(dp) \tilde{f}(p) a_p := a(\sqrt{2\pi} \overline{\tilde{f}}).
\end{equation}
This is nice because now I can just
refer back to section 2.4 to see how
$a(\sqrt{2\pi} \overline{\tilde{f}})$ acts 
on a tensor product on some dense subset in 
the Fock space.

In summary, (3.14) says
$$
\phi(f) = \sqrt{2 \pi } a(\overline{\tilde{f}}) + \sqrt{2 \pi } a^*( \tilde{f}).
$$
(where the constant factors of pi can be taken in and out of
the annihilation and creation operators because $a$ and $a^*$ are
linear in $f \in L^2(\mathcal{M})$.)

Let me also discuss the name "operator valued distribution."
An operator valued distribution is a family
$(\phi(f))_{f \in \mathcal{S}(\mathbb R^4)}$, where
for each $f \in \mathcal{S}(\mathbb R^4)$, the symbol
$\phi(f)$ denotes a linear operator on some Hilbert space $\mathcal{H}$. 
But how does this connect to another notion of 
a distribution, namely a map
$\Phi: \mathcal{S}(\mathbb R^4) \to \mathbb C$, 
with the stereotypical example being the dirac distribution
$\delta_0: \mathcal{S}(\mathbb R^4) \to \mathbb C$ 
centered at $0 \in \mathbb R^4$? 
To see the connection, observe that
we can rewrite the quantum field $(\phi(f))_{f \in \mathcal{S}(\mathbb R^4)}$
as a map: 
$$
\Phi: \mathcal{S}(\mathbb R^4) \to \mathcal{L}(\mathcal{H}).
$$
Rewriting in this way allows me to 
see that a quantum field is just
a distribution, but with values in $\mathcal{L}(\mathcal{H}) =
\{f: \mathcal{H} \to \mathcal{H} \mid f \text{ linear} \}$
instead of $\mathbb C$. 

On this note, one situation that happens a lot
is the following. One writes down an integral
$$
\int_{\mathbb R^4}dp f(p) a^*_p,
$$
and then says that the integral should be interpreted in 
a distributional sense (because the annihilation 
operator is not actually defined at each $p$, and 
even if it were, the vector valued integral would
be difficult to make sense of because the annihiliation 
operators are not bounded operators, so a Bochner interpretation
is not immediate.)
How is this connected to intepreting an analogous 
integral 
$$
\int_{\mathbb R^4} dp f(p) \delta_0(p)
$$
in the sense of distributions? Well, the latter integral is 
actually defined by 
$$
\delta_0(f) =: \int_{\mathbb R^4} dp f(p) \delta_0(p),
$$
because the delta function is not defined 
at the origin, and you can't ignore the singularity at
the origin (as you would for 
$L^p$ functions by ignoring null sets) because 
the null set $\{0\}$ actually affects the value of the integral. 
The main point is this, we've intepreted the original integral 
in a distributional sense, because $\delta_0(f)$ is a well-defined
complex number: it is just $\delta_0(f) = f(0) \in \mathbb C$. 
To see the analogy for the operator valued distributional case, 
just replace the $\delta_0$ by $a$ on the left hand side
and the $\delta_0(p)$ inside the integral on the right hand side by $a^*_p$. 
Then: 
$$
a(f) =: \int_{\mathbb R^4} dp f(p) a^*_p, 
$$
so the right hand side is defined 
by $a(f)$, which is no longer a complex number, 
but an operator. This explains how
the interpretations of the identities used above from section 2.4 of @BrenneckeCQFT
are called 'distributional interpretations.'

#### The unitary representation Gamma

Consider the phrase "strongly continuous unitary representation $\Gamma(U)$
of $\mathcal{P}_+^\uparrow$ on $\mathcal{H} = \mathcal{F}_s(L^2(S_m^+))$."
We understand this phrase through the following discussion. 
Given an abstract group $G$ and a vector space $V$, a
unitary representation (of $G$ on $V$) is a homomorphism 
$\rho: G \to \mathcal{U}(V)$, where $\mathcal{U}(V)$ denotes the set 
of all unitary maps from $V$ to $V$, equipped
with composition as the multiplication operation (or matrix
multiplication). What is a natural topology to put 
on $\mathcal{U}(V)$? Perhaps an operator topology?

Equipping $G$ with a topology, we say that $\rho$ is strongly continuous
if for all $v \in V$
$$G \ni g \mapsto \rho(g)v \in V$$
is continuous. 
For example, if $G = SU(2)$ and $\iota : SU(2) \to U(2)$ is a strongly continuous
unitary representation of $SU(2)$ on $\mathbb C^2$, then
strong continuity means 
$$SU(2) \ni A \mapsto Av \in \mathbb C^2$$
is continuous
for all $v \in \mathbb C^2$. 

Thus, $\Gamma(U): \mathcal{P}_+^\uparrow \to \mathcal{U}(\mathcal{F}_s(L^2(S_m^+)))$
should satisfy 
$$\mathcal{P}_+^\uparrow \ni (a,L) \mapsto \Gamma(U)((a,L))v \in \mathcal{F}_s(L^2(S_m^+))$$
is continuous, where $v$ is a fixed and arbitrary element 
of the Bosonic Fock space built over the mass
shell. Observe that $\Gamma(U)((a,L))$ is a unitary operator on Bosonic
Fock space, so it makes sense that applying it 
to $v$ gives a Bosonic function. 
Observe that $\Gamma(U)$ is not a finite dimensional 
representation because Fock space is 
not finite dimensional. 

It turns out that the unitary representation 
Gamma actually has a name: the second quantization 
of the unitary representation 
$U= (U(a,L))_{(a,L) \in \mathcal{P}_+^{\uparrow}}$. 
Thus, completely understanding $\Gamma(U)$ entails
understanding the representation $U$ of 
the proper Poincaré group $\mathcal{P}_+^{\uparrow}$ 
on $L^2$ of the mass shell $S_m^+$,
which can be seen in
definition (3.4) in the section 
on the quantization of a massive relativistic particle. 
To this end, let me look at the following exercise, which is 
Probem 3.1 (a) in @BrenneckeCQFT. 

::: {.callout-note title="Exercise 1"}
For $(a,L) \in \mathcal{P}_+^{\uparrow}$, let $U(a,L)$ be defined as in (3.4): 
for $\psi \in L^2(S_m^+, \mathcal{B}(S_m^+), \lambda_m)$, we set
$$
(U(a,L)\psi)(p) = e^{ip^{\mu}a_{\mu}} \psi(L^{-1}p) 
$$
for almost every $p \in S_m^+$ and for all $(a,L) \in \mathcal{P}_+^{\uparrow}$.
Show that 
$\mathcal{P}_+^\uparrow \ni (a,L) \mapsto U(a,L) \in \mathcal{U}(L^2(S_m^+))$
defines a strongly continuous, unitary representation 
of $\mathcal{P}_+^\uparrow$ on $L^2(S_m^+) = L^2(S_m^+, \mathcal{B}(S_m^+), \lambda_m)$. 
:::

Proof. Step one is to
verify the homomorphism property
$$
(U((a,L)(a',L'))\psi)(p) = ((U(a,L)U(a',L'))\psi)(p)
$$ {#eq-1}
for all $(a,L), (a',L') \in \mathcal{P}_+^\uparrow$. 
By definition, 
$(a,L)(a',L') = (a+La', LL')$, so we make the appropriate substitution 
on the left hand side of @eq-1.
Then we have by (3.4) that
\begin{align*}
(U(a+La', LL')\psi)(p) = e^{ip^\mu(a+La')_{\mu}}\psi((LL')^{-1}p).
\end{align*}
We compute for the right hand side using (3.4):
\begin{align*}
((U(a,L)U(a',L'))\psi)(p) &= (U(a,L)(U(a',L')\psi(\cdot)))(p) && \text{i.e. composition law}\\
&= (U(a,L)e^{i(\cdot)^\mu a'_{\mu}}\psi(L'^{-1} (\cdot)) )(p) \\
&= e^{ip^\mu a_{\mu}} e^{i(L^{-1}p)^\mu a'_{\mu}} \psi(L'^{-1}L^{-1}(p)) \\
&= e^{i (p^\mu a_\mu + (L^{-1}p)^\mu a'_\mu)} \psi((LL')^{-1}p).
\end{align*}
For the homomorphism property, it remains to prove that 
$$
p^\mu a_\mu + (L^{-1}p)^\mu a'_\mu = p^\mu(a+La')_{\mu}. 
$$
Note the following facts and observations about

##### Interlude about O(1,3)
$O(1,3)$, the group of isometries on Minkowski space, 
of which $L$ is an element by defintion of 
the Poincaré group. First, Minkowski space 
$\mathbb R^4$ is equipped with a bilinear form 
$\eta = \text{diag}({1,-1,-1,-1})$, 
which means that $\eta(x,y) = x^T \eta y$, where $x$ and 
$y$ are column vectors with 4 entries. 
Next, an isometry $L \in O(1,3)$ is a linear map $\mathbb R^4 \to \mathbb R^4$
that preserves the geometry in the sense that
$\eta(Lx,Ly) = \eta(x,y)$ for all $x,y \in \mathbb R^4$. 
Rewriting gives the equation 
$x^TL^T\eta Ly = x^T\eta y$ for all $x$ and $y$, and 
by choosing $x$ and $y$ as the 
various combinations of basis vectors in order
to single out the matrix entries of 
$L^T\eta L$ on the left and $\eta$ on the right, 
the isometry condition on $L$ can be expressed equivalently 
as $L^T \eta L = \eta$. 
Another useful thing to note is that 
$a^\mu b_\mu = a^T \eta b$ for column vectors
$a$ and $b$ in $\mathbb R^4$.

##### End of Interlude, back to the proof. 

Let's rewrite the equation $p^\mu a_\mu + (L^{-1}p)^\mu a'_\mu = p^\mu(a+La')_{\mu}$ 
using $\eta$ as
$$
p^T \eta a + (L^{-1}p)^T \eta a' = p^T \eta (a+La').
$$
So we want to prove that this equation holds, given 
that $L \in O(1,3)$ and 
that $p \in S_m^+$. 
By linearity and cancellation, the equation becomes
$$
(L^{-1}p)^T \eta a' =  p^T \eta La'.
$$
But using that $L^{-1} \in O(1,3)$, which
implies that $(L^{-1})^T \eta L^{-1} = \eta$, which
implies $(L^{-1})^T \eta = \eta L$, 
gives confirmation. 
But why is $L^{-1} \in O(1,3)?$ Well, $L \in 
O(1,3)$ implies 
$L^T \eta L = \eta$, which
implies that $\eta^T = L^T \eta^T L$ because $\eta$ is symmetric, 
which implies that 
$\eta^T L^{-1} = L^T \eta^T$, which implies that
$(L^{-1})^T \eta = \eta L$ after transposing both sides, 
which implies that 
$(L^{-1})^T \eta L^{-1}= \eta$, which
implies that $L^{-1} \in O(1,3)$. This concludes step one, the homomorphism 
property of the representation. 

Next, I'd like to check the unitary property, which
states that for all $(a,L) \in \mathcal{P}_+^\uparrow$,
that $U(a,L)$ is a unitary operator on $L^2(S_m^+)$, which means that
$$
\langle \psi, \phi \rangle_{L^2(S_m^+)} = \langle U(a,L) \psi, U(a,L) \phi \rangle_{L^2(S_m^+)}
$$
for all $\psi, \phi \in L^2(S_m^+)$. 

I'm not super sure if 
functions in $L^2(S_m^+)$ are supposed to have a codomain of $\mathbb C$, 
but I'll guess that for now based on the imaginary 
$i$ in the exponent in the formula (3.4).

\begin{align*}
\langle U(a,L) \psi, U(a,L) \phi \rangle_{L^2(S_m^+)} &= \int_{S_m^+} d\lambda_m(p) \overline{U(a,L)\psi} (p) U(a,L) \phi (p)  \\
&= \int_{S_m^+} d \lambda_m(p) \overline{e^{ip^\mu a_\mu} \psi (L^{-1}p)} e^{ip^\mu a_\mu} \phi(L^{-1}p) \\
&= \int_{S_m^+} d \lambda_m(p)  e^{-ip^\mu a_\mu} \overline{ \psi (L^{-1}p)} e^{ip^\mu a_\mu} \phi(L^{-1}p) \\
&= \int_{S_m^+} d \lambda_m(p) \overline{ \psi (L^{-1}p)} \phi(L^{-1}p) \\
&= \int_{L^{-1}S_m^+} d (\lambda_m \circ L)(h) \overline {\psi(h)} \phi(h) && \text{ change of variables }\\
&= \int_{S_m^+} d \lambda_m (h) \overline {\psi(h)} \phi(h) && \text{ Lemma 3.1 of Brennecke's notes} \\
&= \langle \psi, \phi \rangle_{L^2(S_m^+)}. 
\end{align*}

Here is why $L^{-1}S_m^+ = S_m^+$. 
The definition of the mass shell is $S_m^+ = \{p \in \mathbb R^4: p^T\eta p = m^2, p_0 > 0\}$.
Begin with an element 
$a := L^{-1}p \in L^{-1}S_m^+$. 
Then $L^{-1} \in \mathcal{P}_+^\uparrow$ implies
that $L^{-1}_{00} > 0$ and also $p_0 > 0$, 

##### Interlude on proper Poincaré group

First, it will be helpful to understand the 
following statement found on page 46 of @BrenneckeCQFT: 
If $L \in O(1,3)$, then 
$$
\eta^{\mu \nu} L_{\mu \lambda} L_{\nu \kappa} = 
\eta_{\lambda \kappa} = \eta^{\mu \nu } L_{\lambda \mu} L_{\kappa \nu}.
$$
The conclusion uses the Einstein summation 
convention. As a simple example of that, consider 
two matrices $A \in \mathbb F^{m \times n}$ and 
$B \in \mathbb F^{n \times p}$. Then the formula
for the $(\lambda,\kappa)$ entry, or in other words, the 
$\lambda$-th row and $\kappa$-th column  of the product
$AB$ is $AB_{\lambda \kappa} = \sum_{\nu = 1}^n A^{\lambda \nu}B_{\nu \kappa} = A^{\lambda \nu} B_{\nu \kappa}$,
because entries that appear once up high and 
once down low in the symbolism are taken to be summed over.

To guide myself, let me ask: does $(L^T \eta L)_{\lambda \kappa} = \eta^{\mu \nu} L_{\mu \lambda} L_{\nu \kappa}$?
We have 
\begin{align*}
(L^T \eta L)_{\lambda \kappa} &= ((L^T \eta) L)_{\lambda \kappa}\\
&= (L^T \eta)^{\lambda \nu} L_{\nu \kappa} \\
&= ((L^T)^{\lambda \mu} \eta_{\mu \nu}) L_{\nu \kappa} \\
&= (L^{\mu \lambda} \eta_{\mu \nu}) L_{\nu \kappa} && \text{transpose def} \\
&= (L^{\mu \lambda} \eta_{\nu \mu}) L_{\nu \kappa} && \eta \text{ symmetric} \\
&= (\eta_{\nu \mu} L^{\mu \lambda}) L_{\nu \kappa} && \text{ multiplication commutative} \\
&= \eta^{\nu \mu} L_{\mu \lambda} L_{\nu \kappa},
\end{align*}
so the answer is yes.




<!--
First I want to distill the formula (3.14), 
which is not exactly well-defined as written, 
but corresponds to something that is well-defined.
Thus, I will solve here an exercise in Brennecke's
notes that I expect will transfer to 
the situation of (3.14). The main theme will
be to interpret things in a distributional sense. 

::: {.callout-note title="Exercise 1"}
Suppose that we define the free 
scalar field $(\phi(f))_{f \in S(\mathbb R^4)}$ of mass $m > 0$ 
by 
\begin{equation}
\phi(f) = \int_{\mathbb R} \frac{dt}{(2\pi)^{3/2}} \big(a(e^{i\omega t} \sqrt{2 \omega}^{-1} \hat{f}(t,\cdot/(2\pi))) + a^*(e^{i\omega t} \sqrt{2 \omega}^{-1} \hat{f}(t,\cdot/(2\pi))) \big).
\end{equation}
Identifying heuristically $\phi(f) = \int_{\mathbb R^4} dx \phi_x f(x)$, 
show that this means that 
\begin{equation}
\phi_x = \int_{\mathbb R^3} \frac{dp}{(2\pi)^{3/2}} \left( \frac{e^{-i(\omega(p)t - p\mathbf x)}}{\sqrt{2\omega(p)}} a_p + \frac{e^{i(\omega(p)t - p \mathbf{x})}}{\sqrt{2\omega(p)}}a_p^*  \right)
\end{equation}
for all $x = (t, \mathbf x) \in \mathbb R^4$.
:::

I will use the identities
\begin{equation}
a(f) = \int_{\mathbb R^d} dx \overline{f}(x) a_x
\end{equation}
and 
\begin{equation}
a^*(g) = \int_{\mathbb R^d} dx g(x) a_x^*
\end{equation}
found in section 2.4 of Brennecke's notes. 
They are motivated by the content of Chapter
3 in @Talagrand, which is at most 30 pages of 
reading. 


The conjugate in the right hand side of the first
identity comes from the fact that
the map from $f \maps to a(f)$ is anti-linear. 
Why would this imply the identity above? 
Recall that a map
which is anti-linear satisfies additivity
and conjugate homogenity: $\text{map}(\lambda v) = \overline{}
-->

[
  {
    "objectID": "December2025.html",
    "href": "December2025.html",
    "title": "December 2025",
    "section": "",
    "text": "December 11, 2025\nToday I visited Glimm and Jaffe (1987). It is a technical work. It explains the program of constructive quantum field theory. One idea was the following: partial differential equations generalize ordinary differential equations and quantum field theories generalize partial differential equations. ODEs have one degree of freedom, usually time \\(t\\). PDEs usually have 3 or 4 degrees of freedom, say, \\(t, x, y,\\) and \\(z\\). But quantum fields have infinitely many degrees of freedom.\nODE -&gt; PDE -&gt; Quantum Fields\nRecall briefly that in a classical field, say, a vector field, one attaches a vector to each point in space. The prototypical example of a classical field is an electromagnetic field. In classical mechanics, one observes the trajectory of a particle, and its state is described by 6 degrees of freedom: 3 coordinates of position and 3 coordinates of momentum.\nSo, what are the degrees of freedom for a classical field? Note that each point in space should have a vector attached to it, say, a 3-vector. Wait, what is meant by degree of freedom for the case of a PDE depending on \\(x_1, x_2, x_3, p_1, p_2, p_3\\)? It should mean that, when values for these degrees of freedom are chosen, then all other observables are determined, so there is no more freedom left. In a classical field, then, we expect that the phase space again has something like 6 degrees of freedom. Once position and momentum are fixed, then all the vectors attached to any point in the phase space are determined.\nSo how could it be that a quantum field has infinitely many degrees of freedom? A quantum field is morally an operator attached to each point in space. I feel like there are still only finitely many degrees of freedom. Shouldn’t the operators be determined by whichever point in 4-space you are in?\n\n\nDecember 15, 2025\nToday I spent some time reading Chatterjee (2016). I feel like I have learned a little after spending time on other literature in the Communications of Mathematical Physics and Glimm and Jaffe (1987), but it felt very weak while reading Chatterjee (2016) again.\nI would like to understand the meaning of Chatterjee (2016)’s Theorem 2.1 statement and how it implies the results for the leading term of the free energy for \\(d = 3\\) and \\(d = 4\\), and also why one cannot conclude as much in the \\(d=4\\) case.\nI do see, vaguely, how Theorem 2.1 involves a renormalization (subtracting off \\(d\\) and \\(1/n\\) and so forth). I could see as well the results from section 8 and 9 on the a priori bounds, but they seemed not that impressive because the upper bound was quite huge.\n\n\nDecember 17, 2025\nToday I spent time reading Brennecke (2024) and Brennecke (2025). I’m not sure whether it is appropriate to cite lecture notes, but I mainly wanted to point out that I read Brennecke’s notes today.\nI’ve been mulling over representations. Let \\(G\\) be a group and let \\(V\\) be a vector space. A representation of \\(G\\) is a map \\(\\rho: G \\to GL(V)\\), where \\(GL(V)\\) is the set of invertible linear maps from the vector space \\(V\\) to itself. A finite dimensional representation is a representation where \\(V\\) is finite-dimensional.\nI’m confused about whether finite-dimensional representations arise in the context of the state transformation law for quantum fields. The state transformation law for a quantum field is a representation of the Poincaré group on the state space of the quantum system. In symbols: \\[\\begin{equation}\n(a,L) \\ni \\mathcal{P} \\to U(a,L) \\in \\mathcal{U}(\\mathcal{H}).\n\\end{equation}\\] Thus, \\(U(a,L)\\) is a mapping from the infinite dimensional space \\(\\mathcal{H}\\) to itself. So I don’t see how a finite dimensional representation could arise from the state transformation law.\nMy next guess as for where finite dimensional representations would arise in a quantum field theory is in the field transformation law. That is because one considers \\(n\\) by \\(n\\) matrices to describe the field transformation law. I need to recall field transformations in classical fields. Recall the notion of a vector field. And recall the transformation rules for derivations. I think the point is to describe the fields in different coordinate systems.\nPost Script: as a response to my December 11th note, I believe the infinite degrees of freedom arises from the partial derivative: \\[\\begin{equation}\n\\partial_\\psi f(\\pi) = \\frac{d}{dt} f(\\pi + t \\psi)\n\\end{equation}\\] or something of that sort, where one has the infinite dimensional space of \\(\\psi\\)’s to choose from.\n\n\nDecember 18, 2025\nIn this note I want to summarize what Prof. Brennecke told me today in my thesis meeting.\nWhat Brennecke told me was quite enlightening. In short, he pointed to each term in the Chatterjee formula and said what it meant in terms of the rest of the paper. I wish I had thought of doing that earlier.\nRecall that \\(o(n^d)\\) as \\(n \\to \\infty\\) is a term \\(g(n)\\) that satisfies \\(g(n) / n^d \\to 0\\) as \\(n \\to \\infty\\). For instance, it could be \\(g(n) = n^{d-1}\\) because then there is still an \\(n\\) left in the denominator. Basically any function of \\(n\\) that grows an order more slowly than \\(n^d\\) in the large \\(n\\) limit. For intuition related to the lattice model, recall that there are \\(n^d\\) vertices, so something that is \\(n^{d-1}\\) could be, for instance, the boundary vertices. Maybe as a future exercise, I can create a table with stuff having the various orders in the lattice model.\nRecall also that \\(O(1/n)\\) as \\(n \\to \\infty\\) referes to functions \\(g(n)\\) that are eventually of the same order as \\(1/n\\) when \\(n\\) is large.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.arange(0.1, 2, 0.01)\ny = 1/x\nfig, ax = plt.subplots()\n\nax.plot(x,y)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A visual of 1/n as n goes to infinity\n\n\n\n\n\nSo Chatterjee, in Chatterjee (2016), basically proves the formula: \\[\\begin{equation}\n\\frac{\\log Z}{n^d} = O(1)N^2\\log(g_0^2) + (d-1)\\log \\frac{\\prod_{i=1}^{N-1}j!}{(2\\pi)^{N/2}} + N^2 K_d,\n\\end{equation}\\] as \\(n \\to \\infty\\) and \\(g_0 \\to 0\\).\nThere are three terms on the right hand side. Brennecke says that the second term comes from a Radon Nikodym derivative. Let me think about that. The only sensible place a Radon Nikodym derivative could show up is when comparing the Haar measure on \\(U(N)\\) with the Lebesgue measure on \\(H(N)\\). Wait, no. Perhaps it is when comparing the Lebesgue measure on \\(H(N)\\) with the usual Lebsgue measure on \\(\\mathbb R^{2n}\\). Ok, I looked in Chatterjee (2016) section 11 and let me summarize:\nRecall that the exponential map maps Lie algebra to Lie group. In our context, the Lie algebra is the Hermitian matrices \\(H(N)\\) and the Lie group is the unitary matrices \\(U(N)\\). We already have Haar measure on \\(U(N)\\). Now, what is the only way to use the exponential map to push the Haar measure or pull the Haar measure onto the Hermitian matrices? Well, given a subset \\(A \\subset H(N)\\), we have to send that subset \\(A\\) over to the Lie group via \\(\\psi(\\cdot) = e^{i(\\cdot)}\\), the exponential map (with an i-factor), and measure it according to Haar measure: \\[\\begin{equation}\n\\nu(A) = \\sigma (\\psi(A)),  \n\\end{equation}\\] which is the formula on page 26 of Chatterjee (2016).\nOkay, I’m a bit stuck on how the second term comes from the Radon Nikodym derivative. I’ll continue that discussion later.\nThere is also the \\(N^2K_d\\) term which comes from lattice Maxwell theory, which is a Gaussian theory where you can explicitly compute things (or so I’m told). Finally, I’m not immediately sure where the \\(\\log(g_0^2)\\) term comes from. Brennecke mentioned the discrete Poincaré inequality, so it could come from there. Let me check. I don’t think that relates, rather I think the discrete Poincaré inequality allows one to say something is positive definite, which enables the Gaussian stuff to begin.\nAh wait, there are actually two Poincaré inequalities in Chatterjee (2016). The one I mentioned in the previous paragraph is Lemma 13.1. The other one that I missed is Lemma 10.2. Actually, now I understand another one of Brennecke’s comments, namely that axial guage fixing is required in order to make a smallness of the Wilson action argument, and that without it, there is no path to success. I think I would need to investigate the proof of Lemma 17.2 to be able to see how the first term arises in relation to axial guage fixing and so forth.\n\n\nDecember 19, 2025\nI want to record some observations about the Wilson action and some estimates. Consider \\[\\begin{equation}\nS_{B_n}(U) \\le C n^d \\frac{\\log \\beta }{\\beta}.\n\\end{equation}\\] Let me explain the various terms involved here. \\(Cn^d\\) arises as an estimate on the number of elements in the set \\(|B_n'|\\), which is the set of plaquettes for the box \\(B_n\\). The reciprocal of \\(\\beta\\) term should be moved to the left hand side and related to the usual integrand \\(\\exp(\\beta S_{B_n}(U))\\), which is one factor in the Radon Nikodym derivative \\(\\frac{d\\mu_{YM}}{d\\sigma_n}\\).\nThe \\(\\log \\beta\\) term is a bit harder. From the proof of Theorem 7.1 Chatterjee (2016), we have \\[\\begin{equation}\n\\sigma_{B_n} \\{ U: S_{B_n}(U) \\le |B_n'|/\\beta \\} \\ge (C_1 \\frac{1}{\\sqrt{8 \\beta}})^{C_3 n^d}\n\\end{equation}\\] where \\(C_1\\) is from Corollary 6.3, which gives an estimate on a small ball probability for unitary group, and \\(C_3n^d\\) arises as a term to help approximate the number of edges in the box \\(B_n\\) and to compensate for the term \\(N^2\\) in Corollary 6.3. Multiplying both sides by \\(e^{-|B_n'|}\\), we get \\[\\begin{equation}\ne^{-|B_n'|} \\sigma_{B_n} \\{ U: S_{B_n}(U) \\le |B_n'|/\\beta \\}\n\\ge e^{-|B_n'|} (C_1 \\frac{1}{\\sqrt{8 \\beta}})^{C_3 n^d}.\n\\end{equation}\\] Can the right hand side be written as \\(\\exp(-Cn^d \\log \\beta)\\) for some positive constant \\(C\\) (as in the statement of Theorem 7.1)? Working backwards, yes. The \\(C\\) term is malleable, so write \\(\\exp(-2Cn^d \\log \\beta) = \\exp(-Cn^d \\log \\beta - Cn^d \\log \\beta) = \\exp(-Cn^d \\log \\beta) \\exp( - Cn^d \\log \\beta)\\). One of the terms on the far right hand side can account for \\(e^{-|B_n'|}\\). That is, \\[\\begin{equation} e^{-|B_n'|} \\approx \\exp(-Cn^d \\log \\beta) \\end{equation}\\] Also, by the \\(x^{mn} = (x^m)^n\\) rule for exponents, we have \\(\\exp( - Cn^d \\log \\beta) = (\\exp( \\log \\frac{1}{\\beta}) )^{Cn^d} = (\\frac{1}{\\beta})^{Cn^d}.\\) Then \\[\\begin{equation}\n(\\frac{1}{\\beta})^{Cn^d} \\approx (C_1 \\frac{1}{\\sqrt{8 \\beta}})^{C_3 n^d}\n\\end{equation}\\] I’m tired, so I won’t finish except to write that the product Haar measure (\\(\\sigma_{B_n}\\)) of configurations where the contribution of each plaquette to the Wilson action is on average less than \\(\\beta\\), is lower bounded as \\[\\begin{equation}\n\\sigma_{B_n} \\{ U: S_{B_n}(U) \\le |B_n'|/\\beta \\} \\ge \\exp(-Cn^d \\log \\beta).\n\\end{equation}\\] I still need to figure out how to explain the term \\(\\log \\beta\\) in the first equation in today’s entry.\n\n\nDecember 22, 2025\nIn this post I want to write a detailed proof on the same content from my December 19th post. This follows Sections 6,7, and 8 from Chatterjee (2016).\n\nLemma (from Proof of Thm 7.1):\nSuppose \\(\\beta \\ge 2\\), \\(\\delta \\in (0,\\sqrt N)\\), and \\(8 \\delta^2 = \\frac{1}{\\beta}\\). Then there exists a constant \\(C\\) depending only on \\(N\\) and \\(d\\) such that \\[\\begin{equation}\n\\sigma_{B_n}(\\{ U: S_{B_n}(U) \\le |B_n'|/ \\beta \\}) \\ge e^{-Cn^d \\log \\beta}.\n\\end{equation}\\]\n\n\n\n\n\n\nNoteProof\n\n\n\nThe inequality \\[\\begin{align*}\n\\sigma_{B_n}(\\{ U: S_{B_n}(U) \\le |B_n'|/ \\beta \\}) &\\ge \\prod_{i=1}^{|E_n|} \\sigma(\\{ U: \\lVert I - U \\rVert \\le \\delta \\}) && \\text{where }8 \\delta^2 = \\frac{1}{\\beta}\n\\end{align*}\\] means that under product Haar measure, the probability that the average contribution of plaquettes to the Wilson action being less than \\(\\frac{1}{\\beta}\\), is approximated from below by the probability of edges carrying unitary matrices that are \\(\\delta = \\frac{1}{\\sqrt{8\\beta}}\\)-close to the identity matrix. Next, from the lower bound on the small ball probabilities for unitary matrices, we have \\[\\begin{align*}\n\\prod_{i=1}^{|E_n|} \\sigma(\\{ U: \\lVert I - U \\rVert \\le \\delta \\}) &\\ge \\prod_{i=1}^{|E_n|} C_1 \\delta^{N^2} \\\\\n&= \\prod_{i=1}^{|E_n|} (\\sqrt[N^2]{C_1}^2 \\delta^2)^{N^2/2} \\\\\n&= \\prod_{i=1}^{|E_n|} (\\sqrt[N^2]{C_1}^2 \\frac{1}{8 \\beta})^{N^2/2} \\\\\n&= \\prod_{i=1}^{|E_n|\\frac{N^2}{2}} \\frac{\\sqrt[N^2]{C_1}^2}{8} \\frac{1}{\\beta}.\n\\end{align*}\\] We may assume without loss of generality that \\(C_1 &lt; 1\\) because \\(C_1\\) is a factor for the lower bound in Corollary 6.3. Thus, \\(\\frac{\\sqrt[N^2]{C_1}^2}{8} &lt; 1\\), so taking more powers decreases the value. Also, \\(\\beta \\ge 2\\) by assumption, so taking more powers of \\(\\frac{1}{\\beta}\\) also decreases the value. By Lemma 17.1, we have that \\(|E_n| \\le dn^d\\), so replacing \\(|E_n|\\) by \\(dn^d\\) leads to \\[\\begin{align*}\n\\prod_{i=1}^{|E_n|\\frac{N^2}{2}} \\frac{\\sqrt[N^2]{C_1}^2}{8} \\frac{1}{\\beta} & \\ge \\prod_{i=1}^{\\frac{N^2}{2}dn^d} \\frac{\\sqrt[N^2]{C_1}^2}{8} \\prod_{i=1}^{\\frac{N^2}{2} dn^d} \\frac{1}{\\beta}.\n\\end{align*}\\] Next, observe that we can take enough powers of \\(\\frac{1}{2}\\) to lower bound \\(\\frac{\\sqrt[N^2]{C_1}^2}{8}\\), and the number of powers that are taken depends only on \\(N\\) and \\(d\\), as \\(C_1\\) only depended on \\(N\\). Thus, for some positive constant \\(C\\) depending only on \\(N\\) and \\(d\\), we know that \\[\\begin{align*}\n\\prod_{i=1}^{\\frac{N^2}{2}dn^d} \\frac{\\sqrt[N^2]{C_1}^2}{8} \\prod_{i=1}^{\\frac{N^2}{2} dn^d} \\frac{1}{\\beta} &\\ge \\prod_{i=1}^{\\frac{N^2}{2}dn^d} \\prod_{j=1}^C \\frac{1}{2} \\prod_{i=1}^{\\frac{N^2}{2} dn^d} \\frac{1}{\\beta} \\\\\n& \\ge \\prod_{i=1}^{C \\frac{N^2}{2} dn^d} \\frac{1}{\\beta},\n\\end{align*}\\] where \\(\\beta \\ge 2\\) was used in the last step. Finally, we get \\[\\begin{align*}\n\\prod_{i=1}^{C \\frac{N^2}{2} dn^d} \\frac{1}{\\beta} &= (e^{-\\log \\beta})^{Cn^d} && C \\mapsto C \\frac{N^2}{2} d \\\\\n&= e^{-Cn^d \\log \\beta}.\n\\end{align*}\\] Recalling the beginning of the proof, we conclude \\[\\begin{align*}\n\\sigma_{B_n}(\\{ U: S_{B_n}(U) \\le |B_n'|/ \\beta \\}) &\\ge e^{-Cn^d \\log \\beta}.\n\\end{align*}\\]\n\n\n\n\n\n\n\n\nReferences\n\nBrennecke, Christian. 2024. “Mathematical Quantum Mechanics with Applications.” Lecture Notes. https://www.iam.uni-bonn.de/users/brennecke/home.\n\n\n———. 2025. “Introduction to Constructive Quantum Field Theory.” Lecture Notes. https://www.iam.uni-bonn.de/users/brennecke/home.\n\n\nChatterjee, Sourav. 2016. “The Leading Term of the Yang-Mills Free Energy.”\n\n\nGlimm, James, and Arthur Jaffe. 1987. Quantum Physics: A Functional Integral Point of View."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yang-Mills Lattice Gauge Theory - William’s Explorations",
    "section": "",
    "text": "January 3, 2026\nI’m studying section 12 in Chatterjee (2016), which is titled Some Standard Results About Gaussian Measures. I’d like to understand why \\(Q\\) being a positive definite \\(n\\) by \\(n\\) real matrix implies that \\[x^TQx + v^Tx + C =: P(x) \\ge c \\lVert x \\rVert^2\\] for some positive constant \\(c\\), for all \\(\\Vert x \\rVert\\) sufficiently large, where \\(x = (x_1, \\cdots, x_n) \\in \\mathbb R^n\\). Maybe I should first mention what this is saying. When a real matrix \\(Q\\) is positive definite, it means that the polynomial \\[ \\begin{matrix}\nQ_{11} x_1^2 &+& \\cdots &+& Q_{1n} x_1 x_n\\\\\n\\vdots && \\ddots && \\vdots \\\\\nQ_{n1} x_1x_n &+& \\cdots &+& Q_{nn} x_n^2\n\\end{matrix}\\] is strictly positive for all \\(x \\ne 0\\). So the matrix \\(Q\\) is the coefficient matrix of the degree 2 monomials. Oh yeah, and \\(P(x)\\) above is just a general degree 2 polynomial in the real variables \\(x_1, \\cdots, x_n\\). I’ll mention that the variables commute, so we can just assume that \\(Q\\) is symmetric, because we can break up the coefficients into two equal halves. The main point of all this is that \\(P(x) \\ge c \\lVert x \\rVert^2\\) is a necessary and sufficient criterion for the integrability of a Gaussian density term for a Gaussian measure (see section 12), so knowing that \\(Q\\) being positive definite is equivalent allows you to later bring in stuff about smallest eigenvalues of \\(Q\\), linear algebra stuff, and other information that is not obvious from first glance.\nThis implication of \\(Q\\) positive definite implies \\(P(x) \\ge c \\lVert x \\rVert^2\\) is too hard for my little brain, so as a first step I need to consider an easier case: assume \\(v = 0\\) and \\(C = 0\\), so the polynomial \\(P\\) is just made up of the terms in \\(x^TQx\\). So I want to show that \\[P(x) = x^T Qx \\ge c \\lVert x \\rVert^2\\] for some \\(c &gt; 0\\) and for all \\(\\lVert x \\rVert &gt; r &gt; 0\\), where \\(r\\) is some radius that is big enough.\nLet’s assume that \\[R_* := \\inf_{\\lVert x \\rVert = 1} x^TQx &gt; 0.\\] Hopefully I can prove later on that \\(Q\\) being positive definite implies this infimum statement truly does hold, but I believe \\(Q\\) being symmetric is also needed.\nIf this infimum statement does truly hold, then since the infimum is a lower bound, then for any \\(\\lVert x \\rVert = 1\\), we get the inequality \\[x^TQx \\ge R_*\\] and since \\(\\lVert x \\rVert^2 = 1\\), we also have \\[x^TQx \\ge R_* \\lVert x \\rVert^2.\\]\nThen take some arbitrary \\(x \\in \\mathbb R^n \\setminus \\overline{B}(0,1)\\), that is, \\(\\lVert x \\rVert &gt; 1.\\) Scaling down \\(x\\), we see that \\(\\frac{x}{\\lVert x \\rVert}\\) is on the sphere of radius 1. So it holds that \\[\\frac{x}{\\lVert x \\rVert}^T Q \\frac{x}{\\lVert x \\rVert} \\ge R_* \\lVert \\frac{x}{\\lVert x \\rVert} \\rVert^2.\\] Then multiplying through by \\(\\lVert x \\rVert^2\\), we see that \\[x^T Q x \\ge R_* \\lVert x \\rVert^2.\\] We have thus shown that with \\(c := R_*\\) and \\(r = 1\\), then for all \\(\\lVert x \\rVert \\ge r\\), we have \\(P(x) = x^T Qx \\ge c \\lVert x \\rVert^2,\\) the desired conclusion.\nHere are some other observations that don’t fit anywhere yet:\n\nRandom Oberservations\nObservation 1: \\(c\\lVert x \\rVert^2 = cx_1^2 + \\cdots + cx_n^2.\\)\nObservation 2: Consider the expression \\(x^TQx\\) as being built of \\[x^TQx = \\text{diagonal}(Q,x) + \\text{off-diagonal}(Q,x),\\] where \\[\\text{diagonal}(Q,x) = Q_{11}x_1^2 + \\cdots + Q_{nn} x_n^2\\] and \\[\\text{off-diagonal}(Q,x) = \\sum_{i \\ne j} Q_{ij}x_ix_j.\\]\nObservation 3: I notice that the diagonal entries of \\(Q\\) must be positive. Here’s why. If \\(e_i = (0, \\cdots, 1, \\cdots, 0) \\in \\mathbb R^n\\) is the vector with \\(0\\) at every index besides the \\(i\\)th index, then \\(Q_{ii} = e_i^{T} Q e_i &gt; 0\\), by positive definiteness.\n\n\nFurther Discussion\nI wish I had time to graph some of the simpler cases. For instance, the case of \\(\\mathbb R^n = \\mathbb R^2\\), where we can name the variables \\(x\\) and \\(y\\), and then we can see the conic sections. Then the off diagonal part looks like \\[\\begin{align*}\n\\text{off-diagonal}(Q,(x,y)) = Q_{12}xy + Q_{21}xy,\n\\end{align*}\\] which, when plotted as the graph of the function \\(z(x,y) = (Q_{12}+Q_{21})xy\\) in \\(\\mathbb R^3\\), looks like a hyperbolic parabaloid. The diagonal part, being a quadratic form with positive coefficients, is always positive, and then \\(x^TQx&gt; 0\\) takes the geometric meaning that the negaative part of the hyperbolic parabaloid is dominated by the diagonal part.\n\n\nStill Needed\nNext I need to show that \\(Q\\) being positive definite (and symmetric) implies that \\[R_* := \\inf_{\\lVert x \\rVert = 1} x^TQx &gt; 0.\\]\nThen I need to tackle the case where the linear part \\(v^Tx\\) is non zero and the constant \\(C\\) is also non-zero.\n\n\n\n\n\n\nReferences\n\nChatterjee, Sourav. 2016. “The Leading Term of the Yang-Mills Free Energy.”"
  },
  {
    "objectID": "phone-notes.html",
    "href": "phone-notes.html",
    "title": "Twitter-like feed",
    "section": "",
    "text": "January 6, 2025\nWhen the coupling constant of U(N) lattice gauge theory is small, then beta is big. When beta is big, the format of the Yang mills probability density forces the Wilson action to be very small if there is to be any probability mass associated to a given configuration. The Wilson action being small means that most unitary matrices are equal to the identity matrix. Matrices mostly being equal to identity matrices implies that parallel transporting along plaquettes does not do anything. So the gauge field has no effect. I think that the gauge field having little effect and the coupling constant being small are related concepts. By analogy, smallness of the coupling constant for gravity means that gravity has little role.\nI was previously confused because I noticed that when the coupling constant is large, then the Yang Mills gauge measure is just a product Haar measure. I figured product Haar measure means that there is no interaction, a contradiction to the coupling constant being large. Perhaps the reason that this is not a contradiction is that unitary matrices under Haar measure are not concentrated near the identity matrix, so during parallel transport, the gauge field plays a bigger role. And the gauge field taking stronger role fits with the coupling constant being larger.\n\n\nDecember 24, 2025\nConditional probabilities are where you fix some prior knowledge/variables and then you ask about the probability for the remaining variables.\nThat seems like the right framework for axial gauge fixing. You fix the variables for the tree edges, then figure out the rest of the variables.\n\n\nDecember 25, 2025\nThe log beta term in the formula for the free energy is related to the 1/beta smallness of the Wilson action.\nAlso, even though the math of cqft is very eclectic and broad, it also feels like a niche field. At least I get that feeling when looking at one of the early papers by Fröhlich and Brydges."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website was created on December 9, 2025 to host stuff about my Master’s thesis on and (hopefully) post-Master’s exploration of YM lattice gauge theory, or more generally, the Yang Mills Millenium problem."
  },
  {
    "objectID": "about.html#some-developer-details",
    "href": "about.html#some-developer-details",
    "title": "About",
    "section": "Some developer details:",
    "text": "Some developer details:\nThis website is built using Quarto.\n\nHere are the instructions on how to render to github pages: https://quarto.org/docs/publishing/github-pages.html#render-to-docs.\non how to implement page navigation: https://quarto.org/docs/websites/website-navigation.html\n\nHere is a guide on citations using biblatex: https://www.overleaf.com/learn/latex/Bibliography_management_with_biblatex."
  },
  {
    "objectID": "KleinGordon.html",
    "href": "KleinGordon.html",
    "title": "Wightman Axioms for free scalar quantum field",
    "section": "",
    "text": "Article last updated: January 10, 2026\nI’m writing this article so that I can learn Theorem 3.1 of Prof. Christian Brennecke’s constructive quantum field theory notes Brennecke (2026). The statement of the theorem is as follows.\n\n\n\n\n\n\nNoteTheorem 3.1\n\n\n\nConsider the strongly continuous unitary representation \\(\\Gamma(U)\\) (gamma of U) of \\(\\mathcal{P}_{+}^{\\uparrow}\\) (P plus up) on \\(\\mathcal{H} = \\mathcal{F}_s(L^2(S_m^+))\\) (Bosonic Fock space built over \\(L^2\\) of the mass shell of mass \\(m\\)) with Fock space vacuum \\(\\Omega = (1,0,0,\\cdots) \\in \\mathcal{H}\\) and let \\(\\phi = (\\phi(f))_{f \\in \\mathcal{S}(\\mathbb R^4)}\\) (family of operators indexed by Schwartz functions on \\(\\mathbb R^4\\)) be defined as (3.14): \\[\\begin{equation}\n\\phi(f) = (2\\pi)^{1/2} \\int_{S_m^+} \\lambda_m(dp) \\tilde{f}(p) a_p + (2\\pi)^{1/2} \\int_{S_m^+} \\lambda_m(dp) \\tilde{f}(p) a_p^*.\n\\end{equation}\\] Then \\((\\mathcal{H}, \\Gamma(U), \\Omega, \\phi)\\) satisfies the Wightman axioms and \\[\\begin{equation}\n(\\square + m^2) \\phi = 0\n\\end{equation}\\] in the sense of operator-valued distributions.\n\n\nLet me clarify (3.14) for myself. Recall that the creation and annihilation operators depend on some function \\(f \\in L^2(\\mathcal{M})\\), where in this case \\(\\mathcal{M} = S_m^+\\). Only once you have some \\(f\\) can you talk about an operator from the infinite tensor product space \\(\\mathcal{F}_s\\) to itself. That is why I can write \\[\\begin{equation}\na(\\sqrt{ 2 \\pi } \\tilde{f} ) : \\mathcal{F}_s \\to \\mathcal{F}_s,\n\\end{equation}\\] and this object is defined in section 2.4 in Brennecke (2026).\nNext, I want to phrase (3.14) directly in terms of rigorously defined objects. I’ll use the identities \\[\\begin{equation}\na(f) =: \\int_{\\mathbb R^d} dx \\overline{f}(x) a_x\n\\end{equation}\\] and \\[\\begin{equation}\na^*(g) =: \\int_{\\mathbb R^d} dx g(x) a_x^*\n\\end{equation}\\] found in section 2.4 of Brennecke’s notes. It follows that \\[\\begin{equation}\n(2\\pi)^{1/2} \\int_{S_m^+} \\lambda_m(dp) \\tilde{f}(p) a_p := a(\\sqrt{2\\pi} \\overline{\\tilde{f}}).\n\\end{equation}\\] This is nice because now I can just refer back to section 2.4 to see how \\(a(\\sqrt{2\\pi} \\overline{\\tilde{f}})\\) acts on a tensor product on some dense subset in the Fock space.\n\n\n\n\n\nReferences\n\nBrennecke, Christian. 2026. “Introduction to Constructive Quantum Field Theory.” Lecture Notes. https://www.iam.uni-bonn.de/users/brennecke/home."
  }
]